<p align="center">
<img src="https://avatars.githubusercontent.com/u/1947722" width="300" height="300">
</p>
<h1 align="center">StarryDivineSky</h1>
<p align="center">
    <a href="https://github.com/wuwenjie1992/StarryDivineSky/issues" style="text-decoration:none">
        <img src="https://img.shields.io/github/issues/wuwenjie1992/StarryDivineSky.svg" alt="GitHub issues"/>
    </a>
    <a href="https://github.com/wuwenjie1992/StarryDivineSky/stargazers" style="text-decoration:none" >
        <img src="https://img.shields.io/github/stars/wuwenjie1992/StarryDivineSky.svg" alt="GitHub stars"/>
    </a>
    <a href="https://github.com/wuwenjie1992/StarryDivineSky/network/members" style="text-decoration:none" >
        <img src="https://img.shields.io/github/forks/wuwenjie1992/StarryDivineSky.svg" alt="GitHub forks"/>
    </a>
    <a href="https://github.com/wuwenjie1992/StarryDivineSky/blob/master/LICENSE" style="text-decoration:none" >
        <img src="https://img.shields.io/badge/License-MIT-blue" alt="GitHub license"/>
    </a>

</p>
<h3 align="center">精选了10K+项目，包括机器学习、深度学习、NLP、GNN、推荐系统、生物医药、机器视觉等内容。</h3>
<h3 align="center">Selected more than 10K projects, including machine learning, deep learning, NLP, GNN, recommendation system, biomedicine, machine vision, etc.</h3>
<h3 align="center">让更多优秀的项目被人发现，让更多的人感受开源的魅力。</h3>
<h3 align="center">Let more excellent projects be discovered by people, let more people feel the charm of open source.</h3>
<h3 align="center">持续更新！欢迎🌟star！😀😀😀 Continue to update! Welcome to star! 😀😀😀</h3>

# 目录

- [机器学习与深度学习](#A01_机器学习与深度学习)
- [NLP自然语言处理](#A02_NLP自然语言处理)
  * [大语言对话模型及数据](#大语言对话模型及数据)
- [网络与前后端开发](#A03_网络与前后端开发)
- [机器视觉](#A04_机器视觉)
- [语音识别与合成](#A05_语音识别与合成)
- [推荐系统](#推荐系统)
- [因果推断](#因果推断)
- [金融股票与时间序列](#金融股票与时间序列)
- [强化学习](#强化学习_ReinforcementLearning)
- [生物医药](#生物医药)
- [图数据库 图算法](#图数据库图算法)
- [图神经网络GNN](#图神经网络GNN)
- [大数据](#大数据)
- [虚拟化](#虚拟化)
- [安全与渗透](#安全与渗透)
- [硬件](#硬件)
- [其他项目](#其他项目)

# Tips 注意
* README 文件仅展示了仅一个月新增的前128个git项目。The README file only shows the first 128 git projects added in just one month.
* 完整的项目内容较长，建议clone后阅读或搜索。The file content is long, it is recommended to read or search after cloning.


# Star🌟数变化

* [![关注者](https://starchart.cc/wuwenjie1992/StarryDivineSky.svg)](https://starchart.cc/wuwenjie1992/StarryDivineSky)

# 加入社区

<a href="https://discord.gg/jUkG8kBhE3" style="text-decoration:none" target="_blank">
   <img src="https://img.shields.io/discord/1185098807831171082?color=5865F2&label=discord&labelColor=black&logo=discord&logoColor=white&style=flat-square" alt="加入discord社区"/> 
</a>

# A01_机器学习与深度学习

## A01_机器学习教程

## 其他_机器学习与深度学习

## 分布式机器学习

## 参数优化

## 异常检测

## 梯度提升和树模型

## 特征工程

## 神经网络结构搜索_Neural_Architecture_Search

# A02_NLP自然语言处理

## A01_文本生成_文本对话

### 其他_文本生成_文本对话

### 大语言对话模型及数据

#### Agent代理助手_机器人

##### 

* [BuilderIO/micro-agent](https://github.com/BuilderIO/micro-agent) Micro-agent 是一个 AI 智能体，旨在为你编写（真正有用的）代码。它通过观察你的操作和目标，理解你的意图，并自动生成相应的代码片段或完成编码任务。该项目由 BuilderIO 开发，利用 AI 技术简化开发流程，提高开发效率。Micro-agent 的核心在于其智能代码生成能力，能够根据上下文生成可用的代码，避免了传统代码生成工具的局限性。它可能集成了大型语言模型（LLM），并针对代码生成进行了优化。 使用者可以通过简单的交互，让 Micro-agent 辅助完成编码工作，例如自动生成函数、编写测试用例等。 总体来说，Micro-agent 是一个具有潜力的 AI 辅助编程工具，旨在提升开发者的工作效率。

* [i-am-bee/beeai-framework](https://github.com/i-am-bee/beeai-framework) BeeAI Framework 是一个可以使用 Python 和 Typescript 构建生产级 AI Agent 的框架。它旨在简化 AI Agent 的开发流程，提供结构化的方法来构建复杂的 Agent。该框架的核心是允许开发者定义 Agent 的目标、工具和记忆，并使用编排器来协调 Agent 的行为。BeeAI 强调模块化和可扩展性，方便集成不同的 LLM 和工具。它支持多种记忆类型，包括向量数据库和知识图谱，并提供预构建的工具和模块，如搜索引擎、数据库查询和 API 调用。BeeAI 的目标是让开发者能够快速迭代和部署可靠的 AI Agent，从而解决实际问题。该框架通过提供清晰的架构和易于使用的 API，降低了 AI Agent 开发的门槛。

* [xming521/WeClone](https://github.com/xming521/WeClone) Xming521/WeClone是一个从微信聊天记录创建数字分身的开源项目，欢迎大家star。它提供了一站式解决方案，利用微信聊天记录微调大型语言模型(LLM)来生成数字分身。该项目特色在于使用微信语音消息结合0.5B大小的模型实现高质量的声音克隆。其工作原理是将克隆的声音和语言模型绑定到聊天机器人，从而模拟用户的聊天风格和声音，最终实现数字分身的效果。项目关键词包括：数字克隆、数字分身、数字永生、声音克隆、LLM、大语言模型、微信聊天机器人和LoRA。

* [simstudioai/sim](https://github.com/simstudioai/sim) Sim是一个开源的AI Agent工作流构建器。它允许用户创建和管理复杂的AI Agent流程。Sim的核心在于提供一个灵活的框架，用于连接不同的AI模型、工具和数据源。用户可以通过图形界面或代码定义Agent的行为和交互方式。项目特色包括模块化设计、可扩展性以及易于使用的API。Sim的工作原理是基于预定义的节点和连接，每个节点代表一个特定的任务或功能，例如自然语言处理、数据分析或决策制定。这些节点可以连接在一起，形成一个完整的Agent工作流。Sim支持多种AI模型和工具，包括但不限于大型语言模型（LLM）和自定义脚本。它旨在简化AI Agent的开发和部署过程，使开发者能够快速构建和迭代复杂的AI应用。

* [allenai/lumos](https://github.com/allenai/lumos) Lumos是一个由AllenAI开发的开源项目，旨在研究如何利用统一的数据、模块化的设计和开源的大语言模型来学习智能Agent。该项目提供代码和数据，用于复现和扩展Lumos的研究成果。Lumos的核心思想是构建一个灵活且可扩展的Agent学习框架，通过整合不同来源的数据，并采用模块化的组件设计，使得Agent能够更好地理解和交互环境。项目重点关注如何利用开源LLM作为Agent的核心推理引擎，探索其在各种任务中的应用潜力。Lumos的模块化设计允许研究人员轻松地替换或添加新的组件，例如感知模块、规划模块和执行模块。该项目旨在推动Agent学习领域的发展，并促进开源LLM在智能Agent中的应用。通过Lumos，研究人员可以更方便地进行实验和验证，从而加速Agent学习算法的创新。项目目标是创建一个强大的、可复用的Agent学习平台，促进该领域的开放研究和合作。

* [luo-junyu/Awesome-Agent-Papers](https://github.com/luo-junyu/Awesome-Agent-Papers) 这个GitHub项目luo-junyu/Awesome-Agent-Papers 收集了关于大型语言模型（LLM）Agent的论文，并保持更新。它旨在提供一个全面的资源，涵盖LLM Agent的方法论、应用和挑战。该项目整理了大量相关论文，方便研究人员和开发者快速了解该领域的最新进展。LLM Agent的核心在于利用大型语言模型作为智能体，通过规划、推理和执行动作来完成复杂任务。项目内容包括Agent的架构设计、记忆机制、工具使用、以及在各种场景下的应用，例如游戏、机器人和自动化。此外，该项目还探讨了LLM Agent面临的挑战，如幻觉、可解释性和安全性。Awesome-Agent-Papers 是一个宝贵的资源，可以帮助人们深入理解和开发基于LLM的智能Agent。

* [YoungDubbyDu/LLM-Agent-Optimization](https://github.com/YoungDubbyDu/LLM-Agent-Optimization) 本项目是论文《LLM-Agent优化综述》的阅读清单，旨在整理和优化基于大型语言模型（LLM）的智能体相关研究。项目会持续添加新的论文并改进清单，欢迎大家提出建议和贡献代码。该项目专注于LLM智能体的优化，为研究人员提供一个全面的文献资源。你可以通过该项目了解LLM智能体优化的最新进展和研究方向。项目内容包括一系列相关的论文列表，方便快速查找和学习。欢迎提交PR，共同完善这份LLM智能体优化领域的资源。

* [junchenzhi/Awesome-LLM-Ensemble](https://github.com/junchenzhi/Awesome-LLM-Ensemble) Awesome-LLM-Ensemble项目是一个精选的LLM集成论文列表，旨在为“利用多个大型语言模型：LLM集成综述”提供支持。该项目专注于LLM集成领域，即如何有效地组合多个LLM以提升性能。它收录了大量关于LLM集成的研究论文，方便研究人员查找和学习。通过整理这些论文，该项目旨在帮助人们更好地理解LLM集成的原理、方法和应用。项目特色在于其全面性和专业性，为LLM集成研究提供了一个有价值的资源库。其工作原理是持续收集和整理相关论文，并进行分类和标注，方便用户检索。该项目对于希望了解LLM集成技术的研究人员和从业者来说是一个宝贵的参考资料。

* [i365dev/llm_agent](https://github.com/i365dev/llm_agent) LLMAgent是一个基于大型语言模型(LLM)构建领域特定智能代理的抽象库。它提供核心架构和行为定义，简化了专门代理的开发。该项目利用AgentForge框架进行动态工作流编排，核心在于简化LLM智能代理的构建过程。开发者可以基于此框架，针对特定领域，快速构建具有智能行为的代理。该库专注于提供基础架构和行为模式，使得开发者可以更专注于代理的特定功能实现。AgentForge框架的集成，实现了代理工作流的动态管理和优化。总之，LLMAgent旨在降低LLM智能代理开发的门槛，提高开发效率，并通过AgentForge提供灵活的工作流管理能力。

#### LLM基准测试_评估评测_排行

##### 

* [meta-llama/PurpleLlama](https://github.com/meta-llama/PurpleLlama) Purple Llama 是 Meta Llama 推出的用于评估和提升大型语言模型（LLM）安全性的工具集。该项目旨在帮助开发者识别和缓解 LLM 中存在的安全风险。它可能包含用于检测有害内容生成、评估模型鲁棒性以及增强模型安全性的各种工具和资源。该项目可能提供对抗性测试、红队演练和安全评估框架等功能。通过使用 Purple Llama，开发者可以更好地理解和解决 LLM 相关的安全问题，从而构建更安全可靠的 AI 系统。该项目可能包含代码示例、文档和预训练模型，以方便用户使用和定制。具体工具和方法请参考项目文档。

#### 健康医学大模型及语料库

##### 

#### 其他及垂直领域大模型

##### 

* [datawhalechina/llms-from-scratch-cn](https://github.com/datawhalechina/llms-from-scratch-cn) Datawhalechina/llms-from-scratch-cn项目旨在帮助开发者仅使用Python基础，从零开始构建大型语言模型。项目特色在于通过逐步构建GLM4、Llama3和RWKV6等模型，深入理解大模型的工作原理。该项目提供中文教程，降低了学习门槛，适合希望深入了解LLM内部机制的学习者。通过动手实践，学习者可以掌握大模型的关键技术和实现细节，而不仅仅是使用现成的API。项目内容涵盖了模型架构、训练方法和推理过程等核心概念。学习者可以逐步搭建自己的LLM，并在此过程中获得宝贵的实践经验。该项目是学习和研究LLM的优秀资源，特别适合对LLM底层原理感兴趣的开发者。

* [ed-donner/llm_engineering](https://github.com/ed-donner/llm_engineering) ed-donner/llm_engineering项目是作者LLM工程课程的配套代码库。该项目旨在帮助开发者掌握LLM（大型语言模型）工程技术。它可能包含课程相关的示例代码、notebook、数据集和文档。通过学习该项目，你可以了解如何构建、优化和部署基于LLM的应用程序。项目可能涵盖LLM的选择、提示工程、模型微调、评估以及部署策略等关键方面。具体内容需要查看项目中的实际代码和文档。如果你正在学习LLM工程或者希望提升相关技能，这个项目会是一个不错的学习资源。该项目可能采用Python等常用编程语言，并使用TensorFlow或PyTorch等深度学习框架。请查阅项目文档以获取更详细的信息和使用说明。

* [IBM/Dromedary](https://github.com/IBM/Dromedary) Dromedary是IBM开发的一个项目，旨在构建有帮助、符合伦理且可靠的大型语言模型(LLMs)。它专注于提升LLMs在实际应用中的安全性和可信度。该项目可能包含用于训练、评估和部署LLMs的工具、数据集和方法。Dromedary可能利用特定技术来解决LLMs中常见的偏见、毒性和缺乏透明度等问题。其目标是推动LLMs在各个领域的负责任应用，并确保其输出符合道德标准。具体实现细节和代码可以在GitHub仓库中找到。Dromedary可能探索了新的训练策略或修改了现有的模型架构，以提高LLMs的可靠性和可解释性。该项目可能提供示例和最佳实践，帮助开发者构建更安全、更值得信赖的LLMs应用。Dromedary代表了IBM在人工智能伦理和负责任AI方面的努力。它可能包含对模型行为进行监控和干预的机制。总而言之，Dromedary致力于推动LLMs朝着更积极和负责任的方向发展。

* [datamllab/LongLM](https://github.com/datamllab/LongLM) LongLM项目是一个ICML'24 Spotlight论文对应的开源项目，它提出了一种无需微调即可扩展大型语言模型（LLM）上下文窗口的方法。该项目的核心思想是利用自扩展机制，使LLM能够处理超出其原始上下文长度的输入。具体来说，LongLM通过一种新颖的注意力机制和位置编码策略，在推理过程中动态地扩展模型的上下文窗口。这种方法避免了重新训练LLM的需要，节省了大量的计算资源和时间。项目代码包括了LongLM的实现以及相关的实验脚本，方便研究人员复现论文结果和进一步研究。LongLM的主要优势在于其高效性和易用性，能够快速地提升现有LLM处理长文本的能力，适用于各种需要长上下文理解的任务。该项目为解决LLM上下文长度限制问题提供了一个有前景的解决方案。

* [attentionmech/mav](https://github.com/attentionmech/mav) Model Activity Visualiser (MAV) 是一个用于可视化大型语言模型（LLM）内部工作机制的工具。它专注于展示模型在处理特定输入时的激活模式，帮助用户理解模型如何处理信息。MAV 的核心思想是将模型的内部状态（如注意力权重和激活值）映射到输入文本上，从而直观地展示模型关注的重点。该项目提供了一个交互式界面，允许用户探索不同层、不同头的注意力权重，以及激活值的分布情况。MAV 支持多种 LLM 架构，并提供灵活的配置选项，以便用户根据自己的需求进行定制。通过 MAV，研究人员和开发者可以更深入地了解 LLM 的行为，从而改进模型的设计和性能。项目还包含示例和教程，方便用户快速上手使用。

* [HKUNLP/ChunkLlama](https://github.com/HKUNLP/ChunkLlama) ChunkLlama是一个无需训练即可扩展大型语言模型（LLM）上下文长度的项目，对应论文“Training-Free Long-Context Scaling of Large Language Models”（ICML'24）。它通过一种新颖的chunking方法，允许LLM处理比其原始训练长度更长的输入序列。该方法的核心思想是将长文本分割成多个chunk，然后利用LLM对这些chunk进行并行处理，最后将结果进行整合。ChunkLlama避免了对LLM进行微调或重新训练的需求，因此可以快速且经济高效地扩展现有LLM的上下文窗口。项目提供了论文中使用的数据和代码，方便研究人员复现和进一步研究。该方法尤其适用于需要处理长文档、书籍或其他长篇文本的应用场景。ChunkLlama的优势在于其简单性、高效性和通用性，使其成为扩展LLM上下文长度的一个有吸引力的选择。项目目标是提供一种易于使用且无需额外训练的LLM长文本处理方案。

* [aitomatic/openssa](https://github.com/aitomatic/openssa) OpenSSA是一个基于领域感知神经符号代理（DANA）架构的小型专家代理项目，旨在解决工业问题。它利用LLM进行符号推理和规划，并结合神经组件以实现感知和行动。OpenSSA的核心是DANA架构，该架构将大型语言模型（LLM）与领域知识库相结合，以实现更可靠和可解释的决策。项目特色包括模块化设计、可扩展性以及对特定工业领域的适应性。OpenSSA通过LLM进行高级推理，并通过神经组件处理低级感知和控制任务，从而实现复杂问题的自动化解决。项目目标是提供一个易于使用和定制的框架，使开发人员能够快速构建针对特定工业需求的智能代理。OpenSSA支持多种工业应用，例如流程优化、故障诊断和预测性维护。项目鼓励社区贡献，并提供详细的文档和示例，以帮助用户入门。

* [VILA-Lab/M-Attack](https://github.com/VILA-Lab/M-Attack) M-Attack是一个针对大型语言模型（LLM）的简单但有效的黑盒对抗攻击基线方法，它能够在GPT-4.5/4o/o1等强大的黑盒模型上实现超过90%的攻击成功率。该项目旨在提供一个易于理解和实现的对抗攻击框架，用于评估和提高LLM的鲁棒性。M-Attack的工作原理基于某种策略，能够生成对抗性输入，诱导LLM产生错误或不期望的输出。该项目提供代码和相关资源，方便研究人员复现结果并进行进一步研究。具体细节和实验结果可以在论文https://arxiv.org/abs/2503.10635中找到。M-Attack的成功表明，即使是最先进的LLM也容易受到精心设计的对抗攻击的影响。

* [a-m-team/a-m-models](https://github.com/a-m-team/a-m-models) a-m-team/a-m-models项目是a-m-team在大语言模型领域的探索。该项目可能包含预训练模型、微调脚本、评估工具或其他与LLM相关的资源。具体内容需要查看项目仓库中的代码和文档。项目目标可能是研究LLM的性能、效率或应用。项目特色取决于具体的模型和方法，可能包括创新的训练技术、独特的模型架构或专门的应用领域。工作原理涉及LLM的训练和推理过程，可能使用Transformer架构或其他先进技术。项目可能提供预训练权重、数据集和示例代码，方便用户使用和研究。请查阅项目文档以获取更详细的信息，例如模型的性能指标、训练数据和使用指南。该项目可能对LLM研究人员和开发者有价值。

* [fzp0424/MT-R1-Zero](https://github.com/fzp0424/MT-R1-Zero) MT-R1-Zero是一个基于大语言模型（LLM）的机器翻译项目，其核心在于使用类似于R1-Zero的强化学习方法来提升翻译质量。该项目旨在推进LLM在机器翻译领域的应用，并提供相应的代码实现。主要贡献是提出了一种新的训练范式，通过强化学习优化LLM的翻译能力，使其在特定任务上表现更佳。项目名称来源于其采用的R1-Zero-like强化学习方法。具体实现细节和实验结果请参考相关论文。如果你对使用LLM进行机器翻译，尤其是对强化学习在其中的应用感兴趣，这个项目值得关注。该项目提供了代码，方便研究者复现和进一步探索。

#### 提示词prompt

##### 

#### 智能搜索_RAG

##### 

* [KwaiKEG/KwaiAgents](https://github.com/KwaiKEG/KwaiAgents) KwaiAgents是一个基于大型语言模型（LLMs）的通用信息搜索代理系统。它旨在构建能够自主进行信息收集和利用的智能代理。该项目利用LLMs的强大能力，使代理能够理解用户需求，规划搜索策略，并从各种来源提取相关信息。KwaiAgents的核心目标是实现高效、准确的信息发现和知识整合。该系统可应用于多种场景，例如问答系统、研究助手和决策支持。KwaiAgents提供灵活的框架，允许用户自定义代理的行为和知识库。其设计重点在于可扩展性和模块化，方便集成新的工具和数据源。项目特色包括智能规划、信息过滤和知识融合。KwaiAgents通过迭代搜索和反馈循环不断优化其性能。它代表了利用LLMs构建下一代智能代理的重要一步。

* [Agent-RL/ReSearch](https://github.com/Agent-RL/ReSearch) ReSearch是一个利用强化学习训练LLM进行推理搜索的项目。它通过强化学习教导LLM学会像人类研究者一样，利用搜索来解决复杂问题。该项目使用LLM作为智能体，通过与搜索环境交互，学习如何规划和执行搜索策略。ReSearch的核心思想是让LLM学会分解问题、制定搜索计划、评估搜索结果，并最终找到问题的答案。它通过奖励机制鼓励LLM探索有效的搜索路径，并惩罚无效的搜索行为。项目目标是提升LLM在知识密集型任务中的表现，例如问答、事实核查等。ReSearch提供了一个灵活的框架，可以应用于各种搜索环境和LLM模型。它使用户能够自定义搜索空间、奖励函数和训练策略。该项目为LLM的推理能力提升提供了一个新的思路，并有望在实际应用中发挥重要作用。

* [sunnweiwei/RankGPT](https://github.com/sunnweiwei/RankGPT) RankGPT是一个使用大型语言模型（LLMs）作为重排序代理的项目，荣获EMNLP 2023杰出论文奖。该项目旨在探索ChatGPT等LLMs在搜索任务中的表现，特别是它们作为重排序模型的能力。RankGPT的核心思想是利用LLMs理解查询和文档语义的能力，对初始检索结果进行更精确的排序，从而提升搜索质量。项目通过实验证明，LLMs可以有效提升搜索相关性，尤其是在处理复杂或长尾查询时。RankGPT提供代码和数据集，方便研究人员复现实验结果并进行进一步研究。项目特色在于其简单而有效的方法，即直接利用LLMs进行文档重排序，无需复杂的训练或微调。它展示了LLMs在信息检索领域的巨大潜力，并为未来的研究方向提供了新的思路。该项目主要使用Python语言实现，并依赖于如transformers等流行的深度学习库。RankGPT的代码结构清晰，易于理解和修改，方便用户根据自身需求进行定制。

* [sunnweiwei/RankGPT](https://github.com/sunnweiwei/RankGPT) RankGPT项目是一个基于大型语言模型（LLMs）的搜索结果重排序代理，荣获EMNLP 2023杰出论文奖。该项目旨在探究ChatGPT等LLMs在搜索任务中的表现，并利用它们改进搜索结果的排序。RankGPT的核心思想是将LLMs作为重排序代理，根据LLMs对文档与查询的相关性判断，对初始搜索结果进行重新排序，从而提升搜索质量。项目特色在于其简单而有效的方法，以及对不同LLMs在搜索重排序任务中表现的深入分析。RankGPT支持多种LLMs，并提供了实验代码和数据集，方便研究人员复现和扩展。该项目通过实验证明，LLMs在搜索重排序方面具有潜力，并为未来的研究方向提供了思路，例如如何更好地利用LLMs的知识和推理能力来提升搜索效果。RankGPT的实现主要依赖于prompt工程，通过精心设计的prompt，引导LLMs理解查询意图并评估文档相关性。

* [pat-jj/DeepRetrieval](https://github.com/pat-jj/DeepRetrieval) DeepRetrieval项目旨在利用大型语言模型（LLM）和强化学习（RL）来改进真实搜索引擎和检索器的性能。该项目探索了如何通过RL微调LLM，使其更有效地理解用户查询并检索相关文档。核心思想是利用LLM生成候选文档，然后使用RL优化LLM的检索策略，使其能够更好地排序和选择文档。项目特色在于它直接针对真实搜索引擎，并试图通过LLM和RL的结合来提升实际搜索效果。项目可能包含用于训练和评估LLM检索器的代码、数据集和实验结果。该项目为研究人员和工程师提供了一个平台，用于探索LLM在信息检索领域的应用，并可能为未来的搜索引擎技术发展提供新的思路。它关注的是如何利用LLM的强大语言理解能力来改善传统搜索引擎的检索效果。

* [nightdessert/Retrieval_Head](https://github.com/nightdessert/Retrieval_Head) Retrieval_Head项目是论文“检索头从机制上解释长上下文事实性”的开源代码。该项目旨在通过引入“检索头”这一概念，深入理解大型语言模型（LLM）如何利用长上下文信息来提高事实性。检索头被设计为在LLM内部模拟外部知识检索过程，使其能够显式地访问和利用相关信息。项目核心思想是，通过训练LLM学习使用检索头，可以显著提升模型在长上下文场景下的事实准确性。具体实现包括检索头的架构设计、训练方法以及评估指标。该项目提供了一套完整的实验流程，用于验证检索头在不同模型和数据集上的有效性。通过分析检索头的行为，研究人员可以更好地理解LLM如何处理和整合长上下文信息，从而为改进LLM的事实性和可解释性提供新的思路。项目代码结构清晰，方便研究人员进行修改和扩展。该项目的主要贡献在于提出了一种新的视角来理解LLM的长上下文能力，并提供了一种可行的技术方案来提升模型的事实性。

* [RUC-NLPIR/WebThinker](https://github.com/RUC-NLPIR/WebThinker) WebThinker是一个旨在赋予大型推理模型深度研究能力的项目。它通过模拟人类研究员的思维过程，使模型能够自主地进行信息检索、知识整合和推理验证。该项目主要特色在于其深度研究能力，能够帮助LLM解决复杂问题。WebThinker的工作原理是让LLM扮演研究员，利用搜索引擎和知识库进行信息搜集，并对搜集到的信息进行分析和总结。该项目包含多个组件，例如信息检索模块、知识整合模块和推理验证模块。WebThinker旨在提高LLM在需要深入研究和推理的任务中的表现。它能够处理需要多步骤推理和复杂信息整合的问题。项目目标是让LLM能够像人类研究员一样，自主地进行研究并得出结论。WebThinker为LLM提供了一个更强大的问题解决框架，使其能够应对更具挑战性的任务。该项目使用户能够利用LLM的强大能力进行更深入的研究和分析。

* [iMoonLab/Hyper-RAG](https://github.com/iMoonLab/Hyper-RAG) Hyper-RAG是一个旨在解决大型语言模型（LLM）幻觉问题的项目，它利用超图驱动的检索增强生成（RAG）技术。该项目由Yifan Feng等人开发。Hyper-RAG的核心思想是构建一个超图来表示知识，其中节点代表实体，超边代表实体之间的复杂关系。通过超图结构，Hyper-RAG能够更准确地检索相关信息，从而减少LLM生成不准确或虚假内容的可能性。项目特色在于其超图结构的知识表示和检索方法，能够有效提升RAG系统的性能。该项目为提升LLM在知识密集型任务中的可靠性和准确性提供了一种新的思路。

* [IAAR-Shanghai/SafeRAG](https://github.com/IAAR-Shanghai/SafeRAG) SafeRAG是一个由上海人工智能研究院（IAAR-Shanghai）开发的用于提升检索增强生成（RAG）系统安全性的项目。它旨在解决RAG系统中存在的安全风险，例如提示注入、对抗性示例和信息泄露等问题。SafeRAG通过一系列安全策略和防御机制，增强RAG系统抵抗恶意攻击的能力。该项目包含多种安全模块，用于检测和缓解不同类型的安全威胁。SafeRAG的核心工作原理是监控和过滤输入查询和生成的内容，以防止恶意代码执行和敏感信息泄露。项目提供了一套工具和框架，方便开发者集成到现有的RAG系统中。SafeRAG特别关注大型语言模型（LLM）的安全问题，并提供针对LLM的特定安全措施。项目目标是构建更安全、更可靠的RAG系统，从而提高用户信任度和数据安全性。SafeRAG的代码和文档是开源的，方便社区参与和贡献。它支持多种RAG架构和LLM模型。SafeRAG的评估指标包括攻击成功率和防御有效性。该项目为RAG系统的安全研究和实践提供了一个有价值的平台。

#### 模型微调_对齐及相关数据

##### 

* [sail-sg/oat](https://github.com/sail-sg/oat) OAT是一个研究友好的LLM在线对齐框架，它支持偏好学习和强化学习等多种技术。该项目旨在简化LLM在线对齐的研究过程。OAT包含多种在线对齐算法的实现，方便研究人员进行实验和比较。它提供了一个模块化的设计，允许用户轻松地定制和扩展现有算法。OAT的目标是促进LLM在线对齐领域的研究进展，并提供一个可靠的平台用于开发和评估新的对齐方法。项目特色包括易于使用、高度可扩展和全面的算法支持。OAT的工作原理是基于在线学习范式，通过与LLM的交互不断优化模型。它适用于各种LLM在线对齐任务，例如对话生成和奖励模型训练。OAT的设计注重灵活性和可配置性，以满足不同研究需求。该项目为LLM在线对齐研究提供了一个强大的工具箱。

#### 模型推理部署_解码量化_UI客户端

##### 

* [johnbean393/Sidekick](https://github.com/johnbean393/Sidekick) Sidekick是一个macOS原生应用，它允许用户与本地LLM进行聊天，无需安装其他软件。Sidekick的核心功能是能够利用用户Mac上的文件、文件夹和网站信息进行回复。这个项目基于llama.cpp，这意味着它使用了llama.cpp提供的能力来运行本地LLM。Sidekick旨在提供一个方便快捷的方式，让用户能够利用本地数据进行智能对话，而无需依赖外部服务器或复杂的配置。它通过直接访问本地文件系统，使得LLM能够理解并回答与这些文件内容相关的问题。总而言之，Sidekick提供了一个在macOS上使用本地LLM进行知识检索和对话的简单解决方案。

* [Cloud-Code-AI/BrowserAI](https://github.com/Cloud-Code-AI/BrowserAI) BrowserAI是一个让你在浏览器中运行本地LLM的项目，支持llama、deepseek-distill、kokoro等多种模型。它利用WebGPU技术进行GPU加速，无需服务器或复杂的设置即可运行。项目目标是让每个人都能轻松体验本地AI，并提供一个安全、私密的AI环境。BrowserAI通过将模型转换为WebAssembly格式，并利用浏览器内置的GPU加速能力，实现了快速的推理速度。它还提供了一个友好的用户界面，方便用户与模型进行交互。该项目旨在推动开源AI的发展，让更多人参与到本地AI的探索和应用中。BrowserAI具有离线运行、数据隐私保护、低延迟等优势，为开发者和用户提供了一个强大的本地AI解决方案。

* [SqueezeAILab/KVQuant](https://github.com/SqueezeAILab/KVQuant) KVQuant 是一个旨在实现超长上下文 LLM 推理的项目，通过 KV 缓存量化技术，目标是支持 1000 万上下文长度。该项目基于 PyTorch 实现，专注于降低 KV 缓存的内存占用，从而扩展 LLM 的上下文窗口。其核心思想是在不显著影响模型性能的前提下，对 KV 缓存进行量化。KVQuant 的关键特色包括高效的量化算法和优化的推理引擎。它通过减少存储 KV 缓存所需的比特数，显著降低了内存需求，使得在有限的硬件资源上运行超长上下文 LLM 成为可能。该项目在 NeurIPS 2024 上发表，展示了其在长文本处理方面的潜力。使用 KVQuant，用户可以处理更长的文档、对话和代码，从而解锁更高级的应用场景。该项目提供代码和文档，方便研究人员和开发者复现和改进。

* [tavily-ai/tavily-mcp](https://github.com/tavily-ai/tavily-mcp) Tavily 多客户端协议 (MCP) 是一个旨在简化与多个大型语言模型 (LLM) 交互的框架。它允许开发者通过一个统一的接口与各种 LLM (如 OpenAI、Anthropic、Google 等) 进行交互，无需为每个模型编写单独的代码。MCP 的核心思想是将 LLM 调用抽象为“操作”，并使用“客户端”来处理与特定 LLM 的通信。它支持多种操作，例如文本生成、嵌入和函数调用，并提供自动重试、速率限制和错误处理等功能。该项目旨在解决 LLM 碎片化问题，使开发者能够更轻松地利用不同 LLM 的优势，并降低集成和维护成本。MCP 采用模块化设计，易于扩展和定制，可以根据特定需求添加新的 LLM 或操作。它还提供了一个简单的配置系统，用于管理 API 密钥和其他设置。总而言之，Tavily MCP 是一个强大的工具，可以帮助开发者更有效地利用 LLM，加速 AI 应用的开发。

* [jy-yuan/KIVI](https://github.com/jy-yuan/KIVI) KIVI是一个ICML 2024论文对应的项目，专注于KV缓存的免调优非对称2比特量化。其核心思想是利用KV缓存中值的非对称分布，通过一种无需额外调整的量化方案，实现高效的压缩。KIVI旨在降低大型语言模型（LLM）的内存占用，并提升推理速度。该项目提出的量化方法能够有效减少KV缓存的存储空间，同时保持模型性能。KIVI的关键优势在于其免调优特性，简化了部署过程，降低了使用门槛。项目代码提供了KIVI量化方法的实现，方便研究者和开发者使用。KIVI通过非对称量化策略，更好地适应KV缓存数据的特性，从而实现更高的压缩效率。它为LLM的部署和应用提供了一种高效且易于使用的量化方案。总而言之，KIVI是一个关于KV缓存量化的创新工作，它通过免调优的非对称2比特量化，实现了高效的内存压缩和加速。

* [jongwooko/distillm](https://github.com/jongwooko/distillm) DistiLLM是一个用于大型语言模型（LLM）精简蒸馏的PyTorch官方实现，发表于ICML 2024。该项目旨在通过高效的蒸馏方法，将大型LLM的知识转移到更小的模型中，从而实现更快的推理速度和更低的计算成本。DistiLLM的核心思想是针对性地选择和利用LLM中的关键知识，避免冗余信息的传递。它采用了一种新颖的蒸馏框架，能够有效地保留LLM的性能，同时显著减少模型大小。该项目提供了详细的代码和实验结果，方便研究人员和开发者复现和应用DistiLLM。DistiLLM的优势在于其高效的蒸馏策略和卓越的性能表现，使其成为LLM压缩和加速的理想选择。通过DistiLLM，用户可以轻松地将大型LLM部署到资源受限的环境中，例如移动设备和边缘计算平台。项目代码结构清晰，易于理解和修改，方便用户根据自身需求进行定制。DistiLLM为LLM的实际应用开辟了新的可能性，推动了LLM技术的发展。

#### 法律大模型及语料库

##### 

#### 编程语言大模型及相关项目

##### 

#### 计算测试时推理

##### 

* [theworldofagents/Agentic-Reasoning](https://github.com/theworldofagents/Agentic-Reasoning) Agentic-Reasoning是一个开源项目，旨在探索和实现自主智能体推理能力。该项目受到了OpenAI Deep Research的启发，致力于构建能够像人类一样进行复杂推理的智能体。它提供了一系列工具和框架，帮助开发者构建和评估具有推理能力的智能体。Agentic-Reasoning的核心思想是让智能体能够分解复杂任务、规划行动步骤、并利用外部知识来解决问题。该项目强调智能体的自主性和适应性，使其能够在不同的环境中学习和改进。该项目包含多种推理策略和算法，例如思维链（Chain of Thought）和知识图谱推理。Agentic-Reasoning的目标是推动人工智能领域的发展，使智能体能够更好地理解和解决现实世界的问题。项目鼓励社区参与，共同探索智能体推理的未来方向。开发者可以通过该项目学习到构建智能体的关键技术和方法，并参与到开源社区的贡献中。该项目目前正在积极开发中，未来将推出更多功能和特性。

* [McGill-NLP/nano-aha-moment](https://github.com/McGill-NLP/nano-aha-moment) McGill-NLP/nano-aha-moment 是一个专门为“LLM强化学习”设计的单文件、单GPU、从零开始、高效且全参数调优的库。该项目旨在简化和加速LLM的强化学习过程。其核心特色在于代码简洁，易于理解和修改，方便研究人员快速实验和迭代。项目强调高效性，即使在单个GPU上也能实现较好的性能。它支持对LLM的全部参数进行调优，从而最大化强化学习的效果。该库从零开始构建，避免了对复杂框架的依赖，降低了学习成本。通过这个项目，用户可以更便捷地探索和应用强化学习技术来优化大型语言模型。 总而言之，nano-aha-moment提供了一个轻量级、高效、可定制的平台，助力LLM强化学习研究。

* [Eclipsess/Awesome-Efficient-Reasoning-LLMs](https://github.com/Eclipsess/Awesome-Efficient-Reasoning-LLMs) Eclipsess/Awesome-Efficient-Reasoning-LLMs项目是一个关于提升大型语言模型(LLMs)推理效率的资源集合。它涵盖了各种方法，旨在降低LLMs在推理过程中的计算成本和时间消耗。项目特色在于系统性地整理了相关论文、代码和数据集，方便研究者快速了解该领域进展。这些方法包括但不限于模型压缩（如量化、剪枝、知识蒸馏）、加速推理（如动态推理、Speculative Decoding）以及优化提示工程等。该项目旨在帮助开发者和研究者找到合适的工具和技术，以构建更高效、更经济的LLM应用，并推动LLM在资源受限环境下的部署。它持续更新，追踪最新的研究成果，是学习和探索LLM高效推理的重要资源。

* [nvidia-cosmos/cosmos-reason1](https://github.com/nvidia-cosmos/cosmos-reason1) Cosmos-Reason1项目旨在让模型理解物理常识，并通过长链式思维推理过程，以自然语言生成合适的具身决策。该项目专注于提升模型在物理世界中的常识推理能力，使其能够像人类一样思考并做出决策。模型通过学习大量的物理常识知识，并结合长链式推理，逐步分析问题，最终生成合理的决策方案。项目特色在于其对物理常识的深入理解和长链式推理的应用，使得模型能够更好地模拟人类的思考过程。Cosmos-Reason1的目标是构建一个能够理解物理世界并做出合理决策的智能体。

* [XiaoYee/Awesome_Efficient_LRM_Reasoning](https://github.com/XiaoYee/Awesome_Efficient_LRM_Reasoning) 本项目XiaoYee/Awesome_Efficient_LRM_Reasoning是一个关于大型推理模型高效推理的综述性资源整理。它聚焦于语言、多模态及其他领域的大型推理模型的高效推理方法。项目旨在收集和整理相关论文、代码和其他资源，方便研究者快速了解该领域的发展现状和最新进展。它涵盖了各种提高推理效率的技术，例如模型压缩、知识蒸馏、Prompt优化等。该项目为研究人员提供了一个有价值的资源库，帮助他们探索和开发更高效的大型推理模型。项目维护者会持续更新和维护该资源列表。该项目关注如何让大型推理模型在资源受限的环境下更高效地进行推理。

* [FacebookResearch/sweet_rl](https://github.com/FacebookResearch/sweet_rl) SWEET-RL是由Facebook Research开发的项目，旨在为训练多轮LLM智能体在协作推理任务上提供基准和研究代码。该项目基于论文&quot;SWEET-RL Training Multi-Turn LLM Agents on Collaborative Reasoning Tasks&quot;，专注于提升LLM智能体在需要多轮对话和协作才能完成的任务中的表现。SWEET-RL提供了一套完整的工具，包括环境、智能体和评估指标，方便研究人员复现和扩展相关研究。其核心目标是探索如何利用强化学习（RL）来训练LLM智能体，使其能够更好地进行协作推理。项目特色在于其针对多轮对话和协作推理任务的专门设计，以及提供的基准测试和评估工具。通过SWEET-RL，研究人员可以更有效地训练和评估LLM智能体在复杂协作场景下的能力，推动相关领域的发展。它为LLM智能体在需要复杂交互和推理的应用场景中提供了新的可能性。

* [CJReinforce/PURE](https://github.com/CJReinforce/PURE) PURE项目是论文&quot;Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning&quot;的官方代码实现。该项目专注于解决强化学习中的信用分配问题，提出了一种名为“停止求和”的极简形式信用分配方法。其核心思想是利用过程奖励模型，通过最小化形式的信用分配，实现有效的推理能力。PURE项目的关键在于避免复杂的奖励函数设计，仅依赖过程中的奖励信号进行学习。该方法在多种推理任务上表现出色，证明了其在简化信用分配复杂性方面的有效性。项目代码提供了复现论文实验结果所需的必要组件，方便研究人员进一步探索和应用该方法。PURE的优势在于其简洁性和高效性，为强化学习领域提供了一种新的解决思路，尤其适用于需要复杂推理的任务。

* [LLM360/MegaMath](https://github.com/LLM360/MegaMath) LLM360/MegaMath是一个开源的数学预训练数据集，包含3700亿个token。该项目旨在为大型语言模型（LLM）提供高质量的数学训练数据，从而提升其数学推理能力。MegaMath数据集的构建和发布有助于推动数学领域LLM的研究和发展。它为研究人员提供了一个可访问的、大规模的数学数据集，用于训练和评估模型。通过使用MegaMath，LLM可以学习数学概念、公式和推理技巧，从而在解决数学问题时表现更出色。该项目是LLM360计划的一部分，致力于构建全面的LLM生态系统。MegaMath的开源性质鼓励社区参与，共同改进数据集和相关工具，促进数学LLM的进步。该数据集可能包含各种数学主题和难度级别，为LLM提供了丰富的学习资源。

* [RyanLiu112/GenPRM](https://github.com/RyanLiu112/GenPRM) GenPRM是一个官方代码库，对应论文“GenPRM: Scaling Test-Time Compute of Process Reward Models via Generative Reasoning”。该项目旨在通过生成式推理扩展过程奖励模型(Process Reward Models)的测试时计算规模。GenPRM的核心思想是利用生成模型来生成多个推理过程，并使用过程奖励模型对这些过程进行评估，从而选择最佳的推理路径。这种方法允许在测试时进行更深入的探索，提高模型的性能。项目主要关注如何高效地生成和评估这些推理过程，以实现更好的结果。它可能包含用于训练生成模型、实现过程奖励模型以及执行生成式推理的代码。该项目为研究如何利用生成式方法改进过程奖励模型提供了一个有价值的平台。

* [dllm-reasoning/d1](https://github.com/dllm-reasoning/d1) d1项目是论文“d1: 通过强化学习扩展扩散大语言模型中的推理”的官方实现。它旨在提升扩散大语言模型（Diffusion LLMs）的推理能力。d1的核心思想是使用强化学习来训练模型，使其能够更好地进行推理任务。项目提供了训练和评估d1模型的代码和资源。具体来说，它利用强化学习奖励模型来引导扩散模型的生成过程，从而产生更符合逻辑和推理要求的文本。该项目可能包含预训练模型、训练脚本、评估指标以及相关文档，方便研究者复现论文结果并进一步探索扩散模型在推理方面的潜力。总之，d1项目通过强化学习方法显著提升了扩散大语言模型的推理能力，为相关研究提供了有价值的资源和工具。

## BERT优化

## NLP语料和数据集

## Transformer库与优化

## 关系抽取_信息抽取

## 其他_NLP自然语言处理

## 实体识别NER_意图识别_槽位填充

## 文本分类

## 文本匹配_文本检索_文本相似度

## 文本摘要

## 机器阅读理解

## 知识图谱

## 知识图谱问答KBQA_多跳推理

## 预训练模型

# A03_网络与前后端开发

## JavaScript框架

## 前端开发框架及项目

### iOS_Swift应用开发

### React工具库

### Vue工具库

### 前端项目_其他

### 多工具库支持或纯JS

### 管理面板

## 区块链_智能合约

## 后端开发框架及项目

### JAVA开发

### PHP开发

### 后端项目_其他

## 网络信息服务

### 信息沟通

### 网络代理

### 网络协议

### 网络服务_其他

### 网络爬虫

* [itsOwen/CyberScraper-2077](https://github.com/itsOwen/CyberScraper-2077) CyberScraper-2077是一个强大的网络爬虫项目，它利用大型语言模型（LLM）技术，例如OpenAI、Gemini和Ollama，来实现更智能化的网页数据抓取。该项目的主要特色在于其LLM驱动的网页内容理解能力，可以更准确地识别和提取目标信息。工作原理是结合传统的网页爬取技术与LLM的自然语言处理能力，使爬虫能够理解网页的语义结构，从而更有效地定位和抓取所需数据。项目旨在提供一个灵活且易于使用的工具，帮助用户从各种网站中提取信息，并支持多种LLM平台，方便用户根据自身需求进行选择和配置。该项目适用于需要高度定制化数据抓取解决方案的场景，例如市场调研、竞争情报分析等。

### 资源传输下载

# A04_机器视觉

## 3D视觉生成重建

## 人像_姿势_3D人脸

## 光学字符识别OCR

## 其他_机器视觉

##### 

## 图像恢复

## 图像生成

* [Alpha-VLLM/Lumina-mGPT-2.0](https://github.com/Alpha-VLLM/Lumina-mGPT-2.0) Lumina-mGPT 2.0 是一个独立的自回归图像建模项目，无需依赖大型语言模型（LLM）。它通过将图像编码为离散token序列，然后使用自回归Transformer模型进行训练，从而实现图像生成和编辑等功能。该项目的主要特色在于其简洁的架构和高效的训练方法，使其能够在资源有限的环境下进行图像建模。Lumina-mGPT 2.0 的核心思想是将图像视为一种语言，并利用Transformer模型强大的序列建模能力来学习图像的潜在分布。该项目支持多种图像分辨率，并提供了丰富的实验结果和代码示例，方便用户进行二次开发和应用。它适用于图像生成、图像修复、图像编辑等多种任务，为图像建模领域提供了一种新的思路。Lumina-mGPT 2.0 旨在推动图像建模技术的普及和发展，让更多的人能够参与到图像智能的研究中来。

## 图像风格

## 多模态大模型

* [shikras/shikra](https://github.com/shikras/shikra) Shikra 是一个用于大规模多模态语言模型（MLLM）评估的开源平台。它支持多种模型，包括 LLaVA、MiniGPT-4 和 GPT-4V 等，并提供了一套全面的评估指标，如准确率、一致性和安全性。Shikra 的核心在于其灵活的评估流程，允许用户自定义数据集、提示模板和评估函数。它通过将评估任务分解为多个步骤，并利用分布式计算来加速评估过程。该项目旨在简化 MLLM 的评估，并帮助研究人员和开发者更好地理解和改进他们的模型。Shikra 还提供了一个易于使用的 Web 界面，用于管理评估任务和查看结果。它支持多种数据格式，并允许用户上传自己的数据集。此外，Shikra 具有良好的可扩展性，可以轻松地集成新的模型和评估指标。

* [OpenRobotLab/PointLLM](https://github.com/OpenRobotLab/PointLLM) PointLLM是一个ECCV 2024最佳论文候选项目，旨在赋予大型语言模型（LLM）理解点云的能力。它通过将点云数据转化为LLM可以处理的语言形式，实现了3D视觉和语言的结合。PointLLM的核心思想是利用一种新颖的架构，有效地将点云特征与LLM的文本嵌入空间对齐。项目特色在于其能够使LLM直接理解和推理3D点云场景，从而实现诸如3D场景描述、问答等任务。它无需复杂的3D特定模块，而是充分利用了LLM强大的语言理解和生成能力。PointLLM为开发更智能、更通用的3D视觉系统提供了新的方向，有望在机器人、自动驾驶等领域发挥重要作用。该项目提供代码和模型，方便研究人员复现和进一步研究。

* [MME-Benchmarks/Video-MME](https://github.com/MME-Benchmarks/Video-MME) Video-MME是一个CVPR 2025发布的视频分析多模态大语言模型（MLLMs）的综合评估基准。它是首个此类基准，旨在全面评估MLLMs在视频理解方面的能力。该基准包含多种视频分析任务，并提供了一套标准化的评估指标。Video-MME的目标是推动视频分析领域MLLM的发展，并促进公平的性能比较。它为研究人员提供了一个统一的平台，以测试和改进他们的模型。该项目包含详细的评估协议和数据集信息，方便用户进行实验。Video-MME的出现填补了视频分析MLLM评估领域的空白，将加速相关研究的进展。该项目提供了清晰的文档和示例代码，方便用户上手使用。通过使用Video-MME，研究人员可以更好地了解MLLMs在视频分析中的优势和局限性。该基准的发布将促进视频理解技术的进步。

* [YingqingHe/Awesome-LLMs-meet-Multimodal-Generation](https://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation) 这个项目YingqingHe/Awesome-LLMs-meet-Multimodal-Generation是一个精选的论文列表，专注于基于大型语言模型（LLMs）的多模态生成，涵盖图像、视频、3D和音频等领域。它旨在追踪LLMs在多模态内容生成方面的最新研究进展。项目汇集了相关论文，方便研究人员快速了解该领域的关键技术和发展趋势。该资源库可以帮助研究者深入探索如何利用LLMs生成各种类型的多媒体内容，例如根据文本生成图像、视频或者3D模型。通过学习这些论文，可以了解LLMs如何与不同的模态相结合，实现更丰富和多样化的内容创作。这个项目是LLMs和多模态生成交叉领域的一个宝贵资源。

* [tulerfeng/Video-R1](https://github.com/tulerfeng/Video-R1) Video-R1项目是首个探索在多模态大语言模型（MLLMs）中利用强化学习（R1）进行视频推理的研究。它旨在提升MLLMs理解和推理视频内容的能力。该项目通过强化学习方法，优化模型在视频理解任务中的表现。核心思路是让模型学习如何更有效地利用视频信息进行推理。项目主要关注视频推理，即让模型能够根据视频内容做出合理的判断和预测。Video-R1的出现为视频理解领域的多模态大语言模型研究开辟了新的方向，有望显著提升模型在各种视频相关任务中的性能。该项目强调了强化学习在提升视频推理能力方面的潜力，并提供了一种新的研究思路。具体实现细节和实验结果可以在项目中找到。

* [open-compass/Creation-MMBench](https://github.com/open-compass/Creation-MMBench) Creation-MMBench是一个用于评估多模态大语言模型（MLLMs）在上下文感知创造力方面的基准。它包含超过3000个精心设计的上下文感知多项选择题，旨在测试模型在理解复杂视觉和文本上下文后生成创造性内容的能力。该基准专注于评估模型如何利用上下文信息来产生新颖、有用和令人惊讶的输出。题目涵盖了图像描述、故事续写、视觉问答等多种创造性任务，并包含多个难度级别。Creation-MMBench通过衡量模型在这些任务上的表现，来评估其创造性智能水平。该项目提供详细的评估指标和工具，方便研究人员使用和比较不同模型的性能。它能够帮助研究人员深入了解MLLMs在创造性任务中的优势和不足，并促进相关领域的发展。该基准的独特之处在于其对上下文感知的强调，使其能够更全面地评估MLLMs的创造力。Creation-MMBench为推动多模态大语言模型在创意应用中的发展做出了贡献。

* [MIRA-SJTU/STI-Bench](https://github.com/MIRA-SJTU/STI-Bench) STI-Bench是一个用于评估大型语言模型（MLLMs）在精确时空世界理解能力方面的基准测试项目。它由上海交通大学MIRA实验室开发，旨在探究MLLMs是否能够准确理解和推理现实世界的时空关系。该基准测试包含多种任务，例如时空定位、事件排序和预测等，涵盖了不同粒度和复杂度的时空推理场景。STI-Bench利用合成数据和真实世界数据来评估MLLMs的性能，并提供了一套完整的评估指标。项目特色在于其对时空理解的细粒度评估，能够帮助研究人员深入了解MLLMs在处理时空信息方面的优势和不足。通过STI-Bench，研究人员可以更好地开发和改进MLLMs，使其在需要精确时空推理的应用中表现更佳，例如自动驾驶、机器人导航和智能城市管理等。该项目提供数据集、评估代码和基线模型，方便研究人员进行实验和比较。

## 对象检测_分割

* [OptimalScale/DetGPT](https://github.com/OptimalScale/DetGPT) DetGPT 是一个基于大型语言模型 (LLM) 的开放世界目标检测框架，旨在通过结合 LLM 的推理能力和传统目标检测器的定位精度，实现更强大的检测性能。该项目的主要特色在于其零样本检测能力，无需针对特定类别进行训练即可检测新颖的目标。DetGPT 的工作原理是首先利用 LLM 生成目标描述，然后使用这些描述引导目标检测器进行定位。它采用了一种迭代优化策略，通过交替优化目标描述和检测结果来提高检测精度。项目代码库包含了预训练模型、训练脚本和评估工具，方便用户进行实验和二次开发。DetGPT 适用于各种开放世界目标检测任务，例如图像标注、场景理解和机器人导航等。该项目由 OptimalScale 团队开发并开源，旨在推动开放世界目标检测领域的研究进展。

## 视频生成_补帧_摘要

# A05_语音识别与合成

## 语音合成

## 语音识别与合成_其他

* [krillinai/KrillinAI](https://github.com/krillinai/KrillinAI) KrillinAI是一个基于AI大模型的视频翻译和配音工具，旨在提供专业级的翻译效果。它支持一键部署全流程，简化了操作步骤。该项目能够生成针对不同平台优化的内容，例如YouTube、TikTok和Shorts等。KrillinAI可以帮助用户轻松地将视频内容本地化，并适配抖音、小红书、哔哩哔哩、视频号等国内平台。该工具的核心在于利用LLM（大型语言模型）进行高质量的翻译和配音，从而提升视频的全球传播能力。KrillinAI致力于打造简单易用且功能强大的视频翻译解决方案。

##### 

# 云_虚拟化

# 其他项目

## Android应用

## C/C++程序设计

## Flutter程序

## Go程序设计

## Java程序设计

## Python程序

## Rust程序设计

## 游戏

## 知识管理_wiki知识库

## 终端

## 编辑器

## 计算机编程_数据结构与算法

# 因果推断

# 图数据库图算法

# 图神经网络GNN

## 其他_图神经网络GNN

## 图卷积网络

## 图对抗攻击

## 图嵌入_网络表征学习

## 图机器学习库

## 图注意力机制

## 图监督_半监督_对比学习

## 图聚合_节点聚合

## 图预训练_Pre-TrainingOfGraph

## 异构图_异质图

## 时空网络_交通预测_动态图

# 大数据

## 其他_大数据

## 向量数据库_向量搜索_最近邻搜索

## 数据库管理系统

## 数据搜索引擎

# 安全与渗透

## webshell_shellcode

## 其他_安全与渗透

## 加密_密码破解_字典

## 安卓Android

## 扫描器_资产收集_子域名

## 杀毒免杀_逆向工程

## 漏洞库_漏洞靶场

# 强化学习_ReinforcementLearning

# 推荐系统

## 其他_推荐系统

* [linjc16/Rec-R1](https://github.com/linjc16/Rec-R1) Rec-R1是一个通用框架，旨在通过强化学习桥接大型语言模型（LLMs）和推荐系统。该项目基于论文https://arxiv.org/pdf/2503.24289。它利用强化学习来优化LLM在推荐任务中的表现，从而提升推荐系统的性能。Rec-R1的核心思想是让LLM学习如何更好地理解用户偏好并生成更相关的推荐。该框架具有通用性，可以应用于不同的推荐场景和LLM模型。通过强化学习的训练，LLM能够更好地适应推荐任务的特定需求。Rec-R1提供了一种新的思路，将LLM的强大能力引入到推荐系统中，有望显著改善推荐效果。该项目为研究人员和开发者提供了一个有价值的平台，用于探索LLM在推荐系统中的应用。

## 推荐系统算法库与列表

# 时序与金融

## 时间序列

* [deepcharles/ruptures](https://github.com/deepcharles/ruptures) ruptures是一个Python库，专注于时间序列数据的变化点检测。它提供了一系列算法，用于识别时间序列中统计特性发生显著变化的点。项目特色在于其高效的实现和易于使用的API，支持离线和在线变化点检测。ruptures的核心工作原理是基于不同的统计模型和优化方法，例如动态规划、二分分割、以及基于惩罚的优化方法，来寻找最优的变化点位置。它适用于各种应用场景，如信号处理、金融分析、图像分割等。用户可以通过简单的Python代码调用各种算法，并自定义参数以适应不同的数据特性。该项目文档完善，包含丰富的示例和教程，方便用户快速上手。此外，ruptures还支持可视化结果，帮助用户直观地理解变化点检测的结果。

* [Joeland4/FSatten-SOatten](https://github.com/Joeland4/FSatten-SOatten) FSatten-SOatten项目是论文“Revisiting Attention for Multivariate Time Series Forecasting”的代码和日志。该项目旨在改进多元时间序列预测中的注意力机制。它提出了两种新的注意力变体：FSatten和SOatten。FSatten通过频率选择来关注更重要的频率分量，SOatten则在空间维度上进行注意力分配，捕捉不同变量之间的依赖关系。项目包含复现论文实验结果所需的代码，方便研究者验证和扩展。该项目使用PyTorch实现，并提供了详细的实验设置和数据集信息。通过使用FSatten和SOatten，该项目在多元时间序列预测任务上取得了显著的性能提升，为相关研究提供了新的思路。该项目主要关注提升注意力的有效性，从而改善时间序列预测的准确性。

## 金融股票

# 生物医药

## 其他_生物医药

## 分子

## 基因

## 抗菌肽

## 细胞

## 药物-靶标_药物-药物_化合物-蛋白质_相互作用

## 药物发现_药物设计

## 蛋白质结构

# 硬件

## CPU_RISC-V

## 硬件_其他

