# mystars
个人的github stars，主要是机器学习、深度学习、NLP、GNN、大数据等内容。

### 机器学习
MNN 一个轻量级的深度神经网络推理引擎

Tencent/TNN 移动端高性能、轻量级推理框架，同时拥有跨平台、高性能、模型压缩、代码裁剪等众多突出优势

apache/incubator-tvm 用于深度学习系统的编译器堆栈。它旨在缩小以生产力为中心的深度学习框架与以性能和效率为重点的硬件后端之间的差距。TVM与深度学习框架一起使用，以提供对不同后端的端到端编译

Weights and Biases 使用 W&B 组织和分析机器学习实验

ALiPy 一个基于Python实现的主动学习工具包

Nevergrad 无梯度优化平台

combo 用于机器学习模型组合的 Python 工具箱

google/trax 代码更清晰的神经网络代码库

Oneflow-Inc/oneflow OneFlow是一个以性能为中心的开源深度学习框架。

jonasrauber/eagerpy 编写与PyTorch，TensorFlow，JAX和NumPy本地兼容的代码

rushter/MLAlgorithms 机器学习算法

MLEveryday/100-Days-Of-ML-Code

csuldw/MachineLearning

luwill/machine-learning-code-writing

CDCS 中国数据竞赛优胜解集锦

mlpack/mlpack 快速、灵活的机器学习库

tensorflow/ranking  排名学习在TensorFlow中

scikit-survival 生存分析

leibinghe/GAAL-based-outlier-detection 基于盖尔的异常检测

yzhao062/pyod 异常检测

lavender28/Credit-Card-Score 申请信用评分卡模型

modin-project/modin 通过更改一行代码来扩展加速pandas 

vaexio/vaex 适用于Python的核外DataFrame，以每秒十亿行的速度可视化和探索大型表格数据

cupy/cupy NumPy-like API accelerated with CUDA https://cupy.chainer.org

pythran 将 Python 代码转成 C++ 代码执行 一个 AOT (Ahead-Of-Time - 预先编译) 编译器，大幅度提升性能。

RAPIDS Open GPU Data Science http://rapids.ai

cudf cuDF - GPU DataFrame Library

cuml cuML - RAPIDS Machine Learning Library

cugraph cuGraph - RAPIDS Graph Analytics Library

cusignal cuSignal - RAPIDS Signal Processing Library

AtsushiSakai/PythonRobotics 机器人算法

cuML GPU 机器学习算法

SQLFlow 连接 SQL 引擎的桥接，与机器学习工具包连接

FeatureLabs/featuretools

esa/pagmo2 大规模并行优化的科学库 生物启发式算法和进化算法

geatpy-dev/geatpy 高性能遗传进化算法工具箱

guofei9987/scikit-opt 强大的启发式算法Python模块  遗传算法 粒子群优化 模拟退火 蚁群算法 免疫算法 人工鱼群算法

kingfengji/gcForest Deep forest

interpretml/interpret 训练可解释的机器学习模型和解释黑匣子系统

alexmojaki/heartrate 调试 Python程序执行的简单实时可视化

google-research/mixmatch 集成了自洽正则化的超强半监督学习 MixMatch 

bojone/keras_recompute 通过重计算来节省显存，参考论文《Training Deep Nets with Sublinear Memory Cost》。

yuanming-hu/taichi_mpm 带有切割和耦合（CPIC）的高性能MLS-MPM（基于移动最小二乘法的物质点法）求解器

pytorch/opacus Opacus是一个库，可以使用不同的隐私训练PyTorch模型。

pycaret/pycaret Python中的开源，低代码机器学习库

thuml/Transfer-Learning-Library 用于迁移学习的开源且文档齐全的库。它基于具有高性能和友好API的纯PyTorch。当前支持的算法包括：领域对抗神经网络（DANN）深度适应网络（DAN）联合适应网络（JAN）条件域对抗网络（CDAN）最大分类器差异（MCD）Margin Disparity Discrepancy 保证金差异（MDD）

FedML-AI/FedML 面向研究的联邦学习库。支持分布式计算，移动/IoT设备训练和模拟


### 参数优化

hyperopt/hyperopt 分布式超参数优化

optuna/optuna 超参数优化框架https://optuna.org

WillKoehrsen/hyperparameter-optimization 超参数优化

HDI-Project/BTB Bayesian Tuning and Bandits，auto-tuning系统的一个简单、可扩展的后端系统。

scikit-optimize/scikit-optimize 一个简单高效的库，可最大限度地减少（非常）昂贵且嘈杂的黑盒功能。它实现了几种基于顺序模型优化的方法。

automl/SMAC3 基于序列模型的算法配置 优化任意算法的参数

CMA-ES/pycma 基于CMA-ES 协方差矩阵的自适应策略的Py实现和一些相关的数值优化工具。

SheffieldML/GPyOpt 使用GPy进行高斯过程优化

pytorch/botorch PyTorch中的贝叶斯优化

JasperSnoek/spearmint 机器学习算法的实用贝叶斯优化

facebookresearch/nevergrad 用于执行无梯度优化的Python工具箱

Yelp/MOE 用于现实世界的指标优化的全局黑匣子优化引擎。

fmfn/BayesianOptimization 具有高斯过程的全局优化的Python实现。

dragonfly/dragonfly  用于可扩展的贝叶斯优化

音调：可伸缩超参数调整

ray-project/ray Tune可伸缩超参数调整

keras-team/keras-tuner keras的超参数调整




### 梯度提升

AugBoost 梯度提升

DeepGBM 梯度提升

CatBoost 基于梯度提升对决策树的机器学习方法

GBDT-PL/GBDT-PL 梯度提升

mesalock-linux/gbdt-rs 梯度提升

Xtra-Computing/thundergbm 梯度提升

dmlc/xgboost 梯度提升


### 分布式机器学习

horovod/horovod 分布式训练框架

dask/dask  提供大规模性能 高级并行性

Qihoo360/XLearning

sql-machine-learning/elasticdl

kubeflow/kubeflow

alibaba/euler

Angel-ML/angel

ray-project/ray 快速简单的框架，用于构建和运行分布式应用程序。

Alink 基于Flink的通用算法平台

kakaobrain/torchgpipe pytorch的可扩展的管道并行性库，可以有效地训练大型的，消耗内存的模型。

tensorflow/mesh 简化模型并行化 Mesh TensorFlow: Model Parallelism Made Easier

microsoft/DeepSpeed 一个深度学习优化库，它使分布式训练变得容易，高效和有效。

sql-machine-learning/elasticdl Kubernetes原生的深度学习框架。ElasticDL是一个基于TensorFlow 2.0的Kubernetes原生深度学习框架，支持容错和弹性调度。

uber/fiber 简化AI的分布式计算 该项目是实验性的，API不稳定。

petuum/adaptdl 资源自适应深度学习（DL）培训和调度框架。AdaptDL的目标是使分布式DL在动态资源环境（如共享集群和云）中变得轻松高效。

learning-at-home/hivemind 一个用于在互联网上训练大型神经网络的库

## 图数据库 图算法

Tencent/plato

dgraph-io/dgraph

hugegraph/hugegraph

vtraag/leidenalg

erikbern/ann-benchmarks 最邻近搜索

vesoft-inc/nebula 分布式、可扩展、闪电般的图形数据库

milvus-io/milvus 大规模特征向量的最快相似度搜索引擎

vearch/vearch 用于嵌入式向量高效相似性搜索的分布式系统

dgraph-io/dgraph The Only Native GraphQL Database With A Graph Backend.

vesoft-inc/nebula 开放源代码图数据库，能够托管具有数十亿个顶点（节点）和数万亿条边（具有几毫秒的延迟）的超大规模图。

## 大数据
Qihoo360/Quicksql 体系结构图可帮助您更轻松地访问 Quicksql

seata/seata 简单可扩展的自主事务体系结构

apache/incubator-shardingsphere 分布式数据库中间件生态圈

Tencent/wwsearch wwsearch是企业微信后台自研的全文检索引擎

apache/airflow 一个以编程方式编写，安排和监视工作流的平台

apache/shardingsphere Distributed database middleware 分布式数据库中间件

opencurve/curve 网易自主设计研发的高性能、高可用、高可靠分布式存储系统，具有非常良好的扩展性。

ClickHouse/ClickHouse 一个开源列式数据库系统，允许实时生成数据分析报告。

## 图神经网络GNN
* 图机器学习库
 * stellargraph/stellargraph 星际图机器学习库
 * Deep Graph Library (DGL)
 * alibaba/euler 分布式图深度学习框架。
 * facebookresearch/PyTorch-BigGraph 从大型图形结构化数据生成嵌入
 * rusty1s/pytorch_geometric 用于PyTorch的深度图学习扩展库
 * shenweichen/GraphNeuralNetwork 图神经网络的实现和实验，gcn\graphsage\gat等。
 * THUDM/cogdl 图形表示学习工具包，实现的模型，非GNN基线:如Deepwalk，LINE，NetMF，GNN基线:如GCN，GAT，GraphSAGE
 * imsheridan/CogDL-TensorFlow 图表示学习工具包，使研究人员和开发人员可以轻松地训练和比较基线或自定义模型，以进行节点分类，链接预测和其他图任务。它提供了许多流行模型的实现，包括：非GNN基准，例如Deepwalk，LINE，NetMF；GNN基准，例如GCN，GAT，GraphSAGE。
 * CrawlScript/tf_geometric 高效友好的图神经网络库 节点分类:图卷积网络（GCN）、多头图注意力网络（GAT），链接预测：平均池、SAGPooling，图分类：图形自动编码器（GAE）
 * alibaba/graph-learn 旨在简化图神经网络应用的框架。从实际生产案例中提取解决方案。已在推荐，反作弊和知识图系统上得到应用和验证。
 * BUPT-GAMMA/OpenHINE 异构信息网络嵌入（OpenHINE）的开源工具包。实现的模型包括：DHNE，HAN，HeGAN，HERec，HIN2vec，Metapath2vec，MetaGraph2vec，RHINE。
 * PaddlePaddle/PGL 基于PaddlePaddle的高效灵活的图学习框架
 * THUDM/cogdl 由清华大学计算机系知识工程实验室（KEG）开发的基于图的深度学习的研究工具，基于Python语言和Pytorch库。

ASTGCN 基于注意的时空图卷积网络，用于交通流量预测

danielzuegner/robust-gcn

benedekrozemberczki/ClusterGCN

zhiyongc/Graph_Convolutional_LSTM

Jiakui/awesome-gcn 该存储库用于收集GCN，GAT（图形关注）相关资源。

tkipf/gae

peter14121/intentgc-models 意图gc模型

PetarV-/GAT Graph Attention Networks 

GraphVite 高速、大规模图嵌入

williamleif/GraphSAGE

GeniePath-pytorch

xiangwang1223/neural_graph_collaborative_filtering

tkipf/gae Graph Auto-Encoders

tkipf/gcn

microsoft/gated-graph-neural-network-samples

deepmind/graph_nets 在Tensorflow中构建图网

woojeongjin/dynamic-KG 嵌入动态知识图

awslabs/dgl-ke 高性能，易于使用且可扩展的软件包，用于学习大规模知识图嵌入。

leoribeiro/struc2vec

shenweichen/GraphEmbedding

thunlp/OpenKE

Jhy1993/HAN 异构图注意力网络

thunlp/OpenNE

tkipf/keras-gcn

aditya-grover/node2vec

thunlp/Fast-TransX

thunlp/TensorFlow-TransX

Wentao-Xu/SEEK 知识图谱嵌入框架

thunlp/KB2E

RLgraph 用于深度强化学习的模块化计算图

hwwang55/RippleNet 将知识图谱作为额外信息，融入到CTR/Top-K推荐

THUDM/cogdl 用于图形表示学习的广泛研究平台

klicperajo/ppnp 预测然后传播：图形神经网络满足个性化PageRank

inyeoplee77/SAGPool Self-Attention Graph Pooling torch自我注意力图池化

thunlp/ERNIE 用知识图谱增强 BERT 的预训练效果

autoliuweijie/K-BERT Enabling Language Representation with Knowledge Graph ，已被AAAI2020所录取，是较早的考虑将知识图谱中的边关系引入预训练模型的论文。论文链接：https://arxiv.org/pdf/1909.07606v1.pdf

Malllabiisc/CompGCN 针对多关系有向图的图神经网络

graphdml-uiuc-jlu/geom-gcn 几何图卷积网络 将节点映射为连续空间的一个向量（graph embedding），在隐空间查找邻居并进行聚合。

EstelleHuang666/gnn_hierarchical_pooling Hierarchical Graph Representation Learning 构建了一个多层次的、节点可微分的聚合 GNN 网络。在每一层中，完成信息的抽取，并将当前的图聚合为一个更粗粒度的图，供下一层使用。

limaosen0/Variational-Graph-Auto-Encoders 可变图自动编码器 链接预测

animutomo/gcmc Graph Convolution Matrix Completion 解决推荐系统中 矩阵补全 matrix completion 问题，并引入 side information（节点的额外信息）提升预测效果。

Ruiqi-Hu/ARGA 对抗正则化图自动编码器 Adversarially Regularized Graph Autoencoder，可用于图卷积的链路预测。进化路线 GAE -> VGAE -> ARGA 

brxx122/HeterSumGraph 用于提取文档摘要的异构图神经网络

chuxuzhang/KDD2019_HetGNN KDD2019论文中HetGNN的代码：异构图神经网络 

TAMU-VITA/L2-GCN GCN高效分层训练框架

safe-graph/DGFraud 基于深度图的工具箱，用于欺诈检测

safe-graph/graph-fraud-detection-papers 基于图的欺诈检测论文和资源

xiangwang1223/neural_graph_collaborative_filtering 神经图协同过滤（NGCF）是一种基于图神经网络的新推荐框架，通过执行嵌入传播，在用户项二部图中以高阶连通性的形式对协同信号进行显式编码。

Googlebaba/KDD2019-MEIRec 基于异质图神经网络的用户意图推荐

mori97/JKNet-dgl 跳跃知识网络的dgl实现

lanyunshi/Multi-hopComplexKBQA 查询图生成，用于回答知识库中的多跳复杂问题.提出了一种改进的分阶段查询图生成方法，该方法具有更灵活的生成查询图的方式。在查询图生成的每一步，包含三种预定义的操作：扩展、连接、聚合。

nju-websoft/SPARQA 基于知识库的问题解答,提出了一种新颖的骨架语法来表示一个复杂问题的高级结构。骨架语法本质上是依赖语法的一个选定子集，用于专门表示复杂问题的高级结构。这种专用的粗粒度表示形式由于其简单性而可能具有准确的解析算法，有助于提高下游细粒度语义解析的准确性。

malllabiisc/EmbedKGQA 使用知识库嵌入改进知识图上的多跳问题回答

jwzhanggy/Graph-Bert 学习图形表示只需要注意力机制

aister2020/KDDCUP_2020_AutoGraph_1st_Place KDD KDD CUP 2020自动图形表示学习：第一名解决方案。实现了四种不同的模型GCN、GAT、GraphSage、TAGConv

ChandlerBang/Pro-GNN 鲁棒图神经网络的图结构学习，抗严重干扰。

THUDM/GCC Graph Contrastive Coding for Graph Neural Network Pre-Training 用于图形神经网络预训练的图形对比编码，下游任务：节点分类、图分类
、相似性搜索。

snap-stanford/distance-encoding 距离编码-为结构表示学习设计更强大的GNN，提出了一类与结构相关的特征，称为距离编码(Distance Encoding，DE)，以帮助 GNN 以比 1-WL test 更严格的表达能力来表示任意大小的节点集。

acbull/pyHGT Heterogeneous Graph Transformer 异构图Transformer

acbull/GPT-GNN Generative Pre-Training of Graph Neural Networks 图神经网络的生成式预训练。在预处理阶段，算法会首先随机地遮盖掉图中的一些边和点，利用生成模型来生成（预测）这些边的存在和节点的属性。模型的损失函数会使得预测的结果尽量接近真实的网络结构。这样的话，在GPT-GNN训练完成后，其内部的图神经网络层就可以被拿出来进行调优。

megvii-research/DPGN DPGN: Distribution Propagation Graph Network for Few-shot Learning 分布传播图网络的小样本学习

## 强化学习 Reinforcement Learning

ray-project/ray 快速简单的框架，用于构建和运行分布式应用程序。

astooke/rlpyt

Generative Adversarial User Model

dennybritz/reinforcement-learning

keiohta/tf2rl

rlgraph/rlgraph

deepmind/trfl

Ceruleanacg/Personae

dgriff777/a3c_continuous

google/dopamine

keras-rl/keras-rl

openai/gym

georgezouq/awesome-deep-reinforcement-learning-in-finance 金融市场上使用的那些AI（RL/DL/SL/进化/遗传算法）的集合

google/brain-tokyo-workshop 世界模型 prettyNEAT

google-research/football

tensortrade-org/tensortrade 一个开源强化学习框架，用于训练，评估和部署强大的交易程序。

Baekalfen/PyBoy Game Boy emulator written in Python

google-research/batch_rl 离线强化学习

tensorflow/agents TF-Agents是TensorFlow中的强化学习库

YingtongDou/Nash-Detect 通过Nash强化学习进行鲁棒的垃圾邮件发送者检测

deepmind/acme 强化学习的研究框架，强化学习组件和代理库

huawei-noah/xingtian 刑天（XingTian）是一个组件化的库，用于开发和验证强化学习算法。它支持多种算法，包括DQN，DDPG，PPO和IMPALA等，可以在多个环境中训练代理，例如Gym，Atari，Torcs，StarCraft等。

thu-ml/tianshou 天授是基于纯PyTorch强化学习的平台。与现有的强化学习库主要基于TensorFlow，具有许多嵌套类，不友好的API或速度较慢的现有学习库不同，天守提供了快速的模块化框架和pythonic API，用于以最少的行数构建深度强化学习代理代码。

Jingliang-Duan/Distributional-Soft-Actor-Critic 一种用于连续控制任务的强化学习算法—DSAC，其优势在于减少Q值的过估计并显著改进策略的性能。证明了强化学习中引入分布式回报可显著降低Q值的过估计误差，并定量表明此误差与分布的方差呈反比关系。

## 神经网络结构搜索 Neural Architecture Search

huawei-noah/CARS 华为提出基于进化算法和权值共享的神经网络结构搜索

microsoft/nni 用于自动化机器学习生命周期的开源AutoML工具包，包括功能工程，神经体系结构搜索，模型压缩和超参数调整。

awslabs/autogluon 用于深度学习的AutoML工具包 https://autogluon.mxnet.io

researchmm/CDARTS 循环可微架构搜索

xiaomi-automl/FairDARTS 消除差异化架构搜索中的不公平优势



## NLP自然语言处理
### 文本分类 + Attention机制
  * tcxdgit/cnn_multilabel_classification 基于TextCNN和Attention的多标签分类
  * ilivans/tf-rnn-attention Tensorflow实现文本分类任务的关注机制。
  * skdjfla/toutiao-text-classfication-dataset 中文文本分类数据集 共382688条，分布于15类中。

### 文本摘要/指针生成网络
  * abisee/pointer-generator 使用指针生成器网络进行汇总
  * AIKevin/Pointer_Generator_Summarizer 指针生成器网络：具有关注，指向和覆盖机制的Seq2Seq，用于抽象性摘要。 tensorflow 2.0
  * kjc6723/seq2seq_Pointer_Generator_Summarizer 中文会话中生成摘要总结的项目  tensorflow 2.0
  * steph1793/Pointer_Transformer_Generator tensorflow 2.0
  * magic282/NeuSum 通过共同学习评分和选择句子进行神经文本摘要
  * dmmiller612/bert-extractive-summarizer BERT易于使用的提取文本摘要

### 文本相似度
  * UKPLab/sentence-transformers 句子转换器：使用BERT / RoBERTa / XLM-RoBERTa＆Co.和PyTorch的多语言句子嵌入
  * terrifyzhao/text_matching 常用文本匹配模型tf版本，数据集为QA_corpus，持续更新中
  * Brokenwind/BertSimilarity 基于Google的BERT模型来进行语义相似度计算。
  * wuba/qa_match 58同城推出的一款基于深度学习的轻量级问答匹配工具，它融合领域识别与意图识别，对问答意图进行精确理解。

huseinzol05/NLP-Models-Tensorflow 抽象总结 聊天机器人依赖解析器 实体标记 提取摘要 发电机 语言检测 神经机器翻译 光学字符识别 POS标签 问题答案 句子对 语音转文字 拼写校正 小队问题答案 抽干 文字扩充 文字分类 文字相似度 文字转语音 主题生成器 主题建模 无监督提取摘要 矢量化器 老少少的声码器 可视化 注意Attention

CyberZHG/keras-xlnet XLNet的非官方实现。

bojone/attention  Attention机制的实现tensorflow/keras

ouyanghuiyu/chineseocr_lite 超轻量级中文ocr

LeeSureman/Flat-Lattice-Transformer 中文NER 基于Transformer设计了一种巧妙position encoding来融合Lattice结构，可以无损的引入词汇信息。基于Transformer融合了词汇信息的动态结构，支持并行化计算，可以大幅提升推断速度。

thu-coai/CrossWOZ 大规模的中文跨域任务导向对话数据集.它包含5个领域的6K对话会话和102K语音，包括酒店，餐厅，景点，地铁和出租车。

425776024/nlpcda 一键中文数据增强工具,支持：1.随机实体替换 2.近义词 3.近义近音字替换 4.随机字删除 5.NER类 BIO 数据增强 6.随机置换邻近的字  7.百度中英翻译互转实现的增强  8.中文等价字替换

wac81/textda Python3中文文本的数据增强

zhanlaoban/EDA_NLP_for_Chinese 适合中文语料的数据增强EDA的实现

goto456/stopwords 中文常用停用词表

chatopera/Synonyms 用于自然语言处理和理解的中文同义词。

ShomyLiu/Neu-Review-Rec Pytorch的基于评论文本的深度推荐系统模型库。DeepCoNN(WSDM'17)、D-Attn(RecSys'17)、ANR(CIKM'18)、NARRE(WWW'18)、MPCN(KDD'18)、TARMF(WWW'18)、CARL(TOIS'19)、CARP(SIGIR'19)、DAML(KDD'19)

ShannonAI/service-streamer 服务流媒体 BERT服务,每秒处理1400个句子的BERT服务.

squareRoot3/Target-Guided-Conversation 目标指导的开放域对话,在开放域的聊天中目标引导.

weizhepei/CasRel 一种用于关系三重提取的新颖级联二进制标记框架.

qiufengyuyi/sequence_tagging 使用bilstm-crf，bert等方法进行序列标记任务

microsoft/unilm UniLM-NLP及更高版本的统一语言模型预训练

airaria/TextBrewer 基于PyTorch实现的NLP任务知识蒸馏工具包，适用于多种模型结构，支持自由组合各种蒸馏策略，并且在文本分类、阅读理解、序列标注等典型NLP任务上均能获得满意的效果。 

czhang99/SynonymNet 基于多个上下文双向匹配的同义实体发现

PRADO 用于文档分类的投影注意网络 性能媲美BERT，但参数量仅为1/300 tensorflow/models/tree/master/research/sequence_projection

rikdz/GraphWriter 基于图Transformer从知识图谱中生成文本

Big Bird 稀疏注意力机 随机注意力机制+局部注意力机制+全局注意力机制 PurdueCAM2Project/TensorFlowModelGardeners/official/nlp/projects/bigbird/

DC-BERT: Decoupling Question and Document for Efficient Contextual Encoding 双重 BERT 模型的解耦上下文编码框架 shawroad/NLP_pytorch_project/Text_Ranking/DC_Bert_Ranking/

fushengwuyu/chinese_spelling_correction 中文文本纠错模型：bert语言模型+字音字形相似度 、MLM、seq2seq

stanford-futuredata/ColBERT ColBERT: 基于上下文（contextualized）的后期交互的排序模型 Efficient and Effective Passage Search via Contextualized Late Interaction over BERT 兼顾匹配的效率和doc中的上下文信息

ymcui/Chinese-ELECTRA 中文ELECTRA预训练模型 其中ELECTRA-small模型可与BERT-base甚至其他同等规模的模型相媲美，而参数量仅为BERT-base的1/10

ymcui/Chinese-XLNet 面向中文的XLNet预训练模型

salesforce/pytorch-qrnn 准循环神经网络Quasi-Recurrent Neural Network,基于使用实例可以比高度优化的 NVIDIA cuDNN LSTM 实现2到17倍快

ChenghaoMou/pytorch-pQRNN pQRNN 结合一个简单的映射和一个quasi-RNN编码器来进行快速并行处理。pQRNN模型表明这种新的体系结构几乎可以达到BERT级的性能，尽管只使用1/300的参数量和有监督的数据。

### Transformer优化
  * laiguokun/Funnel-Transformer Transformer优化，一种新的自我注意模型，可以将隐藏状态的序列逐渐压缩为较短的状态，从而降低了计算成本。
  * mit-han-lab/hardware-aware-transformers 用于高效自然语言处理的硬件感知型Transformers.实现高达3倍的加速和3.7倍的较小模型尺寸，而不会降低性能。
  * mit-han-lab/lite-transformer 具有长距离短距离注意的Lite transformer
  * DeBERTa：注意力分散的增强解码的BERT，使用两种新颖的技术改进了BERT和RoBERTa模型，显着提高了模型预训练的效率和下游任务的性能。
  * allenai/longformer 用于长文档的类似BERT的模型
  * Tencent/TurboTransformers a fast and user-friendly runtime for transformer inference on CPU and GPU

### BERT优化
  * google-research/bert Bidirectional Encoder Representations from Transformers 来自Transformers的双向编码器表示法
  * google-research/ALBERT 用于语言表达自我监督学习的Lite BERT
  * bojone/bert-of-theseus BERT 模型压缩方法 ,theseus(忒修斯之船 如果忒修斯的船上的木头被  逐渐替换，直到所有的木头都不是原来的木头，那这艘船还是原来的那艘船吗？),将原始大模型切分为多个大模块，固定大模型权重，训练时随机替换为小模块,充分训练后，将小模型继续微调。
  * brightmart/albert_zh 使用TensorFlow 进行自我监督学习语言表示的Lite Bert的实现预训练的汉语模型
  * bert4keras 更清晰、更轻量级的keras版bert
  * huawei-noah/Pretrained-Language-Model 华为诺亚方舟实验室开发的预训练语言模型及其相关优化技术NEZHA是一种经过预训练的中文语言模型，可以在多项中文NLP任务上实现最先进的性能TinyBERT是一种压缩的BERT模型，推理时可缩小7.5倍，加快9.4倍
  * Lisennlp/TinyBert 基于华为的TinyBert进行修改的，简化了数据读取的过程，方便我们利用自己的数据进行读取操作。
  * epfml/collaborative-attention 整合多头注意力,任何经过预训练的注意力层重新配置为协作注意力层。
  * thunlp/ERNIE 用知识图谱增强 BERT 的预训练效果 
    * 1) 对于抽取并编码的知识信息，研究者首先识别文本中的命名实体，然后将这些提到的实体与知识图谱中的实体进行匹配。研究者并不直接使用 KG 中基于图的事实，相反他们通过知识嵌入算法（例如 TransE）编码 KG 的图结构，并将多信息实体嵌入作为 ERNIE 的输入。基于文本和知识图谱的对齐，ERNIE 将知识模块的实体表征整合到语义模块的隐藏层中。
    * 2) 与 BERT 类似，研究者采用了带 Mask 的语言模型，以及预测下一句文本作为预训练目标。除此之外，为了更好地融合文本和知识特征，研究者设计了一种新型预训练目标，即随机 Mask 掉一些对齐了输入文本的命名实体，并要求模型从知识图谱中选择合适的实体以完成对齐。
 * ZhuiyiTechnology/WoBERT 以词为基本单位的中文BERT（Word-based BERT）
 * autoliuweijie/FastBERT FastBERT：具有自适应推断时间的自蒸馏BERT pip install fastbert
 * alexa/bort 论文 Optimal Subarchitecture Extraction for BERT. “ BERT的最佳子体系结构提取”的代码。Bort是用于BERT架构的最佳子集，它是通过对神经架构搜索应用完全多项式时间近似方案（FPTAS）提取的。 Bort的有效（即不计算嵌入层）大小是原始BERT大型体系结构的5.5％，是净大小的16％。它在CPU上也比基于BERT的速度快7.9倍，并且比体系结构的其他压缩变体和某些非压缩变体性能更好。与多个公共自然语言理解（NLU）基准上的BERT-large相比，它的平均性能提高了0.3％至31％。
 * ymcui/MacBERT MacBERT是经过改进的BERT，具有新颖的MLM作为校正预训练任务，从而减轻了预训练和微调的差异。


## 推荐系统

shenweichen/DeepCTR

ChenglongChen/tensorflow-DeepFM

cheungdaven/DeepRec

lyst/lightfm

tensorflow/recommenders TensorFlow Recommenders is a library for building recommender system models using TensorFlow.

oywtece/dstn

shenweichen/DSIN

facebookresearch/dlrm 深度学习推荐模型（DLRM）的实现

vze92/DMR Deep Match to Rank Model for Personalized Click-Through Rate Prediction DMR：Matching和Ranking相结合的点击率预估模型

kang205/SASRec 源于Transformer的基于自注意力的序列推荐模型

shichence/AutoInt 使用Multi-Head self-Attention进行自动的特征提取

xiangwang1223/neural_graph_collaborative_filtering 神经图协同过滤

UIC-Paper/MIMN 点击率预测的长序列用户行为建模的实践

motefly/DeepGBM 结合了 GBDT 和神经网络的优点，在有效保留在线更新能力的同时，还能充分利用类别特征和数值特征。DeepGBM 由两大块组成，CatNN 主要侧重于利用 Embedding 技术将高维稀疏特征转为低维稠密特征，而 GBDT2NN 则利用树模型筛选出的特征作为神经网络的输入，并通过逼近树结构来进行知识蒸馏。

shenweichen/DeepMatch 用于推荐和广告的深度匹配模型库。训练模型和导出用户和项目的表示向量非常容易，可用于ANN搜索。

LeeeeoLiu/ESRM-KG 关键词生成的基于电商会话的推荐模型

zhuchenxv/AutoFIS 自动特征交互选择的点击率预测模型

pangolulu/exact-k-recommendation 解决推荐中带约束的Top-K优化问题

Scagin/NeuralLogicReasoning 神经协同推理,提出了一种新的神经逻辑推荐（NLR）框架，能够将逻辑结构和神经网络相结合，将推荐任务转化为一个逻辑推理任务。

ZiyaoGeng/Recommender-System-with-TF2.0 CTR预言论文进行复现，包括传统模型（MF，FM，FFM等），神经网络模型（WDL，DCN等）以及序列模型（DIN）。

allenjack/HGN 用矩阵分解的形式捕捉用户的长期兴趣，同时将短期兴趣进行拆分，分为group-level以及instance-level的，通过Hierarchical Gating来处理group-level的信息,item-item的乘积来捕捉商品之间的关系。

THUwangcy/ReChorus 用于Top-K推荐的通用PyTorch框架，具有隐式反馈，尤其是用于研究目的。BPR\NCF\Tensor\GRU4Rec\NARM\SASRec\TiSASRec\CFKG\SLRC\Chorus

RUCAIBox/CIKM2020-S3Rec 自我推荐学习，用于具有互信息最大化的顺序推荐

chenchongthu/SAMN 社交注意力记忆网络在推荐系统中的应用

Lancelot39/KGSF 基于知识图谱语义融合改进会话推荐系统
Improving Conversational Recommender Systems via Knowledge Graph based Semantic Fusion

DeepGraphLearning/RecommenderSystems 顺序推荐 基于维度的推荐 社交推荐

FeiSun/BERT4Rec 基于BERT的顺序推荐



## 金融股票 时间序列

QUANTAXIS/QUANTAXIS 量化金融策略框架

ricequant/rqalpha 从数据获取、算法交易、回测引擎，实盘模拟，实盘交易到数据分析，为程序化交易者提供了全套解决方案

cedricporter/funcat 将同花顺、通达信、文华财经麦语言等的公式写法移植到了 Python

georgezouq/awesome-deep-reinforcement-learning-in-finance 金融市场上使用的那些AI（RL/DL/SL/进化/遗传算法）的集合

wangshub/RL-Stock 如何用深度强化学习自动炒股。

tensortrade-org/tensortrade 一个开源强化学习框架，用于训练，评估和部署强大的交易程序。

bsolomon1124/pyfinance 为投资管理和证券收益分析而构建的Python分析包。

arrigonialberto86/deepar Amazon于2017年提出的基于深度学习的时间序列预测方法

fjxmlzn/DoppelGANger 使用GAN共享网络时间序列数据：挑战，初步承诺和未解决的问题，IMC 2020（最佳论文入围）


## 虚拟化
jesseduffield/lazydocker docker 简单终端 UI

KubeOperator/KubeOperator 

rancher/k3s Lightweight Kubernetes. 5 less than k8s. https://k3s.io

docker-slim/docker-slim 请勿更改Docker容器映像中的任何内容并将其最小化30倍

silenceshell/docker_mirror 发现国内加速的docker源。

## 网络爬虫 下载
soimort/you-get youtube下载

shengqiangzhang/examples-of-web-crawlers python爬虫例子

itgoyo/Aria2  突破百度云限速合集

PanDownloadServer/Server 百度云PanDownload的个人维护版本

## 语音
JasonWei512/Tacotron-2-Chinese 中文语音合成

TensorSpeech/TensorflowTTS Tensorflow 2的实时最新语音合成

audier/DeepSpeechRecognition 基于深度学习的中文语音识别系统

athena-team/athena 基于序列到序列的语音处理引擎的开源实现



## 其他
modichirag/flowpm TensorFlow中的粒子网格模拟N体宇宙学模拟

huihut/interview C/C++ 技术面试基础知识总结

barry-ran/QtScrcpy Android实时显示控制软件 

minivision-ai/photo2cartoon 人像卡通化探索项目

hugozanini/realtime-semantic-segmentation 使用TensorFlow.js实施RefineNet以在浏览器中执行实时实例分割

deezer/spleeter 人声分离模型

cfzd/Ultra-Fast-Lane-Detection 论文“ 超快速结构感知深度车道检测 ”的实现

kexinhuang12345/DeepPurpose 最新的深度学习方法的药物-靶标相互作用和特性预测工具包,及其在药物再利用，虚拟筛选，QSAR等方面的应用

bennettfeely/bennett ztext 易于实现的3D网页排版。适用于每种字体。

DaveJarvis/keenwrite 基于Java的桌面Markdown编辑器，具有实时预览，字符串插值和公式

vinayak-mehta/present 基于终端的演示工具，具有颜色和效果。

occlum/occlum 蚂蚁集团自研的开源可信执行环境（Trusted Execution Environments，简称 TEE） OS 系统 Occlum ,大幅降低 SGX 应用开发的门槛.机密计算（Confidential Computing）使得数据始终保持加密和强隔离状态，从而确保了用户数据的安全和隐私。

matazure/mtensor 一个tensor计算库, 支持cuda的延迟计算
